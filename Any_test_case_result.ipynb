{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "__Any_test_case_validator",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mastdev/pos_tag/blob/main/Any_test_case_result.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ix5T1_utZbQH",
        "outputId": "32182af2-2df6-4bd6-bfd4-f637e77d88ed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPvas13KkpRX"
      },
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import xml.etree.ElementTree as et\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdMfvV22aX5J"
      },
      "source": [
        "##Pre Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcE9pCeDMVbU"
      },
      "source": [
        "path='/content/drive/MyDrive/Ai_project_hmm/Train-corpus' # replace with the path of your training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRNQTAjOOrax"
      },
      "source": [
        "dict_pos=[]\n",
        "for root_dir,dirs,files in os.walk(path):\n",
        "    for file in files:\n",
        "        if file.endswith('.xml'):\n",
        "            file_path=os.path.join(root_dir,file)\n",
        "            tree=et.parse(file_path)\n",
        "            root=tree.getroot()\n",
        "            for serials in root.findall('.//s'):\n",
        "                num=serials.attrib.get('n')\n",
        "                sentence=''\n",
        "                prev_tag=''\n",
        "                for words in serials.findall('.//'):\n",
        "                    if (words.tag=='w' or words.tag=='c') and words.text != None:\n",
        "                        w=words.text\n",
        "                        w=w.lower()\n",
        "                        word=w.replace(' ','')\n",
        "                        term=words.attrib.get('c5')\n",
        "                        \n",
        "                        string=word+'_'+term+' '\n",
        "                        sentence+=string\n",
        "                \n",
        "                #dict_pos stores sentences as a list\n",
        "                dict_pos.append(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUT7VvSz-Dze"
      },
      "source": [
        "## Initialisation with Evaluation of Probability Matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_iW8cwgatMH"
      },
      "source": [
        "transition_matrix = {} # [tag][tag] -> value , 61*61\n",
        "probability_matrix = {} # [tag][word] -> value , 61,x\n",
        "initial_matrix = {}  # emission probability stored 61*1\n",
        "tag_dict=[] # stores all the possile tags\n",
        "word_dict={} # stores all the possible words in the traning corpus\n",
        "new_word = \"#un#\" # assignign new words that do not exists in traning corpus\n",
        "cardinal_word = \"#un1\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVV1S50mPerG"
      },
      "source": [
        "# the probability value when ambiguos tags like NN1-VBZ so NN1 assigned 0.85 probability and VBZ is assigned 0.15 probability\n",
        "p=[0.85,0.15]\n",
        "\n",
        "#smoothening value used where transitional probabilites are 0 \n",
        "smoothening_val=0.001\n",
        "\n",
        "#sentence wise processing\n",
        "for sent in dict_pos:\n",
        "\n",
        "  word_tag_list=sent.split(' ')\n",
        "  cnt=0; # stores the cnt of words in sentences\n",
        "\n",
        "  for word_tag in word_tag_list:\n",
        "    if len(word_tag)==0:\n",
        "      continue\n",
        "\n",
        "    word,tag=word_tag.split('_')\n",
        "    tag_list=tag.split('-') # tag_list stores list of all possible tags assigned to the word\n",
        "    if len(tag_list)==1:\n",
        "      tag_list.append(tag_list[0])\n",
        "    if word.isdecimal():\n",
        "        word = cardinal_word\n",
        "    if word not in word_dict:\n",
        "      word_dict[word]=1\n",
        "\n",
        "    #if the word is the starting of the sentence\n",
        "    if cnt==0:\n",
        "      i=0\n",
        "      for tag in tag_list:\n",
        "        if tag not in initial_matrix:\n",
        "          initial_matrix[tag]=0\n",
        "        initial_matrix[tag]+=p[i]\n",
        "        i+=1\n",
        "        \n",
        "    # if not the forst word of sentence    \n",
        "    else:\n",
        "      j=0\n",
        "      for prev_tag_m in prev_tag:\n",
        "        if prev_tag_m not in transition_matrix: # calculating transitional probabilities of the cur_tag and prev_tag\n",
        "            transition_matrix[prev_tag_m]={}\n",
        "        i=0\n",
        "        for tag in tag_list:\n",
        "          if tag not in transition_matrix[prev_tag_m]:\n",
        "            transition_matrix[prev_tag_m][tag]=0\n",
        "          transition_matrix[prev_tag_m][tag]+=p[j]*p[i]\n",
        "          i+=1\n",
        "        j+=1\n",
        "\n",
        "    # word|tag frequency\n",
        "    j=0\n",
        "    for tag in tag_list:\n",
        "      if tag not in probability_matrix:\n",
        "        probability_matrix[tag]={}\n",
        "      if word not in probability_matrix[tag]:\n",
        "        probability_matrix[tag][word]=0\n",
        "      probability_matrix[tag][word]+=p[j]\n",
        "      j+=1\n",
        "\n",
        "    cnt+=1\n",
        "    prev_tag=tag_list\n",
        "\n",
        "tag_dict=[key for key in probability_matrix] \n",
        "\n",
        "# we introduce a loading factor for the unknown words that are outside the corpus\n",
        "load = {}\n",
        "for i in tag_dict:\n",
        "    x = 0.001\n",
        "    if i=='NP0' :\n",
        "        x=20\n",
        "    load[i] = x;\n",
        "\n",
        "for tag in tag_dict:\n",
        "    min_key = max(probability_matrix[tag],key = probability_matrix[tag].get)\n",
        "    probability_matrix[tag][new_word]=load[tag]*probability_matrix[tag][min_key]\n",
        "sum=math.fsum(initial_matrix.values())\n",
        "\n",
        "#converting frequency count to probabilities    \n",
        "for key in initial_matrix:\n",
        "  initial_matrix[key]/=sum\n",
        "\n",
        "for prev_tag in transition_matrix:\n",
        "  sum=math.fsum(transition_matrix[prev_tag].values())\n",
        "  for tag in transition_matrix[prev_tag]:\n",
        "    transition_matrix[prev_tag][tag]/=sum\n",
        "\n",
        "for tag in probability_matrix:\n",
        "  sum=math.fsum(probability_matrix[tag].values())\n",
        "  for word in probability_matrix[tag]:\n",
        "    probability_matrix[tag][word]/=sum\n",
        "\n",
        "for tag in tag_dict:\n",
        "  for nexttag in tag_dict:\n",
        "    if nexttag not in transition_matrix[tag]:\n",
        "      transition_matrix[tag][nexttag]=smoothening_val\n",
        "  if tag not in initial_matrix:\n",
        "    initial_matrix[tag]=smoothening_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQuvAN95DHST",
        "outputId": "8aea8774-cc98-46a3-9756-6775241faa26"
      },
      "source": [
        "for i in tag_dict:\n",
        "    for j in probability_matrix[i]:\n",
        "        if j=='it':\n",
        "            print(i+\" \"+str(probability_matrix[i][j]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NN1 4.703317740033223e-05\n",
            "PNP 0.22806853710658248\n",
            "UNC 3.603112541562804e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9u3r11uCV98"
      },
      "source": [
        "## Prediction on Test using Viterbi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2GNqhrkyFOf"
      },
      "source": [
        "show_dict = [\"Nikhil is registered in artificial intelligence course .\"] #type your sentence\n",
        "show_dict.append(\"I am registered in artificial intelligence course .\")\n",
        "show_dict.append(\"He is registered in artificial intelligence course .\")\n",
        "show_dict.append(\"I am registered in AI course .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd3WvV1tzE0X",
        "outputId": "5bd98bfc-bb97-4cf2-c7c6-71b34bb22c70"
      },
      "source": [
        "c=0\n",
        "inc=0\n",
        "processed=0\n",
        "x=[]\n",
        "y=[]\n",
        "\n",
        "import time\n",
        "tic = time.clock()\n",
        "\n",
        "for sent in show_dict:\n",
        "  #sentencewise hmm model\n",
        "\n",
        "  word_list=sent.split(' ') # stores the word_tag pairs\n",
        "  delta_mat={} # stores the max probabilties with sequence ending at different tag at current word\n",
        "  delta_ancestor={} # delta_ancestor[i][tag] stores the parent of previos child at ith state with max probabiltiy of sequence ending at tag\n",
        "  cnt=0 # cnt the number of words\n",
        "  target=[] # stores the sentencewise target tags\n",
        "\n",
        "  # adding all tags as key to delta_mat\n",
        "  for tag in tag_dict:\n",
        "    if tag not in delta_mat:\n",
        "      delta_mat[tag]=0\n",
        "  \n",
        "  for word in word_list:\n",
        "    if len(word)==0:\n",
        "      continue\n",
        "    word = word.lower()\n",
        "    target.append(word);\n",
        "    if word.isdecimal():\n",
        "        word = cardinal_word\n",
        "    #first word of sentence\n",
        "    if cnt==0:\n",
        "\n",
        "      # p(word|tag)*p(tag) for all tags being stored in \n",
        "      for curtag in tag_dict:\n",
        "        delta_mat[curtag]=initial_matrix[curtag]\n",
        "\n",
        "        if word not in word_dict:\n",
        "          w=new_word\n",
        "        else:\n",
        "          w=word\n",
        "        if w not in probability_matrix[curtag]:\n",
        "          delta_mat[curtag]=0\n",
        "        else:\n",
        "          delta_mat[curtag]*=probability_matrix[curtag][w]\n",
        "\n",
        "    else:\n",
        "      # for all tags max( p(tag|prev_tag)*p(sequence ending at prev_tag) ) * p(word|tag)\n",
        "      new_delta_mat={}\n",
        "      for curtag in tag_dict:\n",
        "\n",
        "        #if word doen't exist as word_curtag pair in train\n",
        "        if word not in word_dict:\n",
        "          w=new_word\n",
        "        else:\n",
        "          w=word\n",
        "        \n",
        "        z=0\n",
        "        for prevtag in tag_dict:\n",
        "          val=transition_matrix[prevtag][curtag]\n",
        "\n",
        "          #val is the value of transition from prev to cur\n",
        "          if z<(delta_mat[prevtag]*val):\n",
        "            z=max(delta_mat[prevtag]*val,z)\n",
        "            prob_tag=prevtag\n",
        "          # taking the max probabilty in x and the probable sequence is ending with prrob_tag\n",
        "        dum=0;\n",
        "        if w in probability_matrix[curtag]:\n",
        "          dum=probability_matrix[curtag][w]\n",
        "\n",
        "        new_delta_mat[curtag]=z*dum\n",
        "\n",
        "        #creating the key of current iteration\n",
        "        if cnt not in delta_ancestor:\n",
        "          delta_ancestor[cnt]={}\n",
        "        #creating the current tag key in delta_ancestor[cnt]\n",
        "        if curtag not in delta_ancestor[cnt]:\n",
        "          delta_ancestor[cnt][curtag]=''\n",
        "\n",
        "        delta_ancestor[cnt][curtag]=prob_tag\n",
        "      delta_mat=new_delta_mat\n",
        "\n",
        "      #normalising delta_mat as the probability values may reduce to a very low order\n",
        "      delta_mat_sum = math.fsum(delta_mat.values())\n",
        "      for i in delta_mat:\n",
        "        delta_mat[i]/=delta_mat_sum\n",
        "    cnt+=1\n",
        "  \n",
        "  #end tag stores the ending tag of the most probable sequence\n",
        "  end_tag=max(delta_mat,key=delta_mat.get)\n",
        "\n",
        "  cnt-=1\n",
        "\n",
        "  #retrieving the most probable sequence\n",
        "  solution=[]\n",
        "  solution.append(end_tag)\n",
        "  while cnt>0:\n",
        "    end_tag=delta_ancestor[cnt][end_tag]\n",
        "    solution.append(end_tag)\n",
        "    cnt-=1\n",
        "  solution.reverse()\n",
        "\n",
        "  for i in range(len(word_list)):\n",
        "      print(word_list[i]+\"_\"+solution[i],end = \" \");\n",
        "  print()\n",
        "\n",
        "toc = time.clock()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nikhil_NP0 is_VBZ registered_VVN in_PRP artificial_AJ0 intelligence_NN1 course_NN1 ._PUN \n",
            "I_PNP am_VBB registered_VVN in_PRP artificial_AJ0 intelligence_NN1 course_NN1 ._PUN \n",
            "He_PNP is_VBZ registered_VVN in_PRP artificial_AJ0 intelligence_NN1 course_NN1 ._PUN \n",
            "I_PNP am_VBB registered_VVN in_PRP AI_UNC course_NN1 ._PUN \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcXDALaS2U7z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}